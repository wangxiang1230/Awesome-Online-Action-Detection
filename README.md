# Awesome Online Action Detection: [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)


### <span id = "oad-survey"> Survey </span>
- <span id = "2200">[Survey-2022]</span> [**Online human action detection and anticipation in videos: A survey**](https://doi.org/10.1016/j.neucom.2022.03.069) - Xuejiao Hu et al, `Neurocomputing 2022`.
  
### <span id = "oad-2023"> 2023 </span>
- <span id = "2305">[MiniROAD]</span> [**MiniROAD: Minimal RNN Framework for Online Action Detection**](https://openaccess.thecvf.com/content/ICCV2023/papers/An_MiniROAD_Minimal_RNN_Framework_for_Online_Action_Detection_ICCV_2023_paper.pdf) - Joungbin An et al, `ICCV 2023`. [[code]](https://github.com/jbistanbul/MiniROAD)
- <span id = "2305">[E2E-LOAD]</span> [**E2E-LOAD: End-to-End Long-form Online Action Detection**](https://arxiv.org/abs/2306.07703) - Shuqiang Cao et al, `ICCV 2023`. [[code]](https://github.com/sqiangcao99/E2E-LOAD)
- <span id = "2304">[MAT]</span> [**Memory-and-Anticipation Transformer for Online Action Understanding**](https://arxiv.org/abs/2308.07893) - Jiahao Wang et al, `ICCV 2023`. [[code]](https://github.com/Echo0125/Memory-and-Anticipation-Transformer)
- <span id = "2303">[Contrastive-based]</span> [**Online Action Detection with Learning Future Representations by Contrastive Learning**](https://ieeexplore.ieee.org/abstract/document/10220027) - Haitao Leng et al, `ICME 2023`.
- <span id = "2302">[HCM]</span> [**HCM: Online Action Detection With Hard Video Clip Mining**](https://ieeexplore.ieee.org/abstract/document/10246422) - Siyu Liu et al, `TMM 2023`.
- <span id = "2301">[JOADAA]</span> [**JOADAA: joint online action detection and action anticipation**](https://arxiv.org/abs/2309.06130) - Mohammed Guermal et al, `ArXiv 2023`.
  
### <span id = "oad-2022"> 2022 </span>
- <span id = "2209">[SCOAD]</span> [**SCOAD: Single-frame Click Supervision for Online Action Detection**](https://openaccess.thecvf.com/content/ACCV2022/papers/Ye_SCOAD_Single-frame_Click_Supervision_for_Online_Action_Detection_ACCV_2022_paper.pdf) - Na Ye et al, `ACCV 2022`.[[code]](https://github.com/zstarN70/SCOAD)
- <span id = "2208">[TwinLSTM]</span> [**TwinLSTM: Two-channel LSTM Network for Online Action Detection**](https://www.computer.org/csdl/proceedings-article/icpr/2022/09956717/1IHoVAhk2Ag) - Yunfei Han et al, `ICPR 2022`.
- <span id = "2207">[Uncertainty-Based]</span> [**Uncertainty-Based Spatial-Temporal Attention for Online Action Detection**](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136640068.pdf) - Hongji Guo et al, `ECCV 2022`.
- <span id = "2206">[TeSTra]</span> [**Real-time Online Video Detection with Temporal Smoothing Transformers**](https://arxiv.org/abs/2209.09236) - Yue Zhao et al, `ECCV 2022`.[[code]](https://github.com/zhaoyue-zephyrus/TeSTra)
- <span id = "2205">[CWC-Trans]</span> [**A Circular Window-based Cascade Transformer for Online Action Detection**](https://arxiv.org/abs/2208.14209) - Shuqiang Cao et al, `ArXiv 2022`.
- <span id = "2204">[GateHUB]</span> [**GateHUB: Gated History Unit with Background Suppression for Online Action Detection**](https://arxiv.org/abs/2206.04668) - Junwen Chen et al, `CVPR 2022`.
- <span id = "2203">[Colar]</span> [**Colar: Effective and Efficient Online Action Detection by Consulting Exemplars**](https://arxiv.org/abs/2203.01057v2) - Le Yang et al, `CVPR 2022`.[[code]](https://github.com/VividLe/Online-Action-Detection)
- <span id = "2202">[PPKD]</span> [**Progressive Privileged Knowledge Distillation for Online Action Detection**](https://arxiv.org/abs/2011.09158) - Peisen Zhao et al, `PR 2022`.
- <span id = "2201">[Continual Transformers]</span> [**Continual Transformers: Redundancy-Free Attention for Online Inference**](https://arxiv.org/abs/2201.06268) - Lukas Hedegaard et al, `ArXiv 2022`.[[code]](https://github.com/lukashedegaard/continual-transformers)



### <span id = "oad-2021"> 2021 </span>
- <span id = "2101">[OadTR]</span> [**OadTR: Online Action Detection with Transformers**](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_OadTR_Online_Action_Detection_With_Transformers_ICCV_2021_paper.pdf) - Xiang Wang et al, `ICCV 2021`.[[code]](https://github.com/wangxiang1230/OadTR)
- <span id = "2102">[LSTR]</span> [**Long Short-Term Transformer for Online Action Detection**](https://proceedings.neurips.cc/paper/2021/file/08b255a5d42b89b0585260b6f2360bdd-Paper.pdf) - Mingze Xu et al, `NeurIPS 2021`.[[code]](https://github.com/amazon-research/long-short-term-transformer)
- <span id = "2103">[TFN]</span> [**Temporal Filtering Networks for Online Action Detection**](https://www.sciencedirect.com/science/article/pii/S0031320320304982) - Hyunjun Eun et al, `PR 2021`.
- <span id = "2104">[WOAD]</span> [**WOAD: Weakly Supervised Online Action Detection in Untrimmed Videos**](https://openaccess.thecvf.com/content/CVPR2021/html/Gao_WOAD_Weakly_Supervised_Online_Action_Detection_in_Untrimmed_Videos_CVPR_2021_paper.html) - Mingfei Gao et al, `CVPR 2021`.[[code]](https://github.com/salesforce/woad-pytorch)
- <span id = "2105">[IDN-Extend]</span> [**Learning to Discriminate Information for Online Action Detection: Analysis and Application**](https://arxiv.org/abs/2109.03393) - Sumin Lee et al, `ArXiv 2021`.
- <span id = "2106">[IED]</span> [**Information Elevation Network for Fast Online Action Detection**](https://arxiv.org/abs/2109.13572) - Sunah Min et al, `ArXiv 2021`.
- <span id = "2107">[empirical study]</span> [**An empirical study on temporal modeling for online action detection**](https://arxiv.org/abs/2001.07501) - Wen Wang et al, `Complex & Intelligent Systems 2021`.
- <span id = "2108"></span> [**Exploring Temporal Context and Human Movement Dynamics for Online Action Detection in Videos**](http://cvsp.cs.ntua.gr/publications/confr/Vasileiou_EUSIPCO21_Enhancing_temporal_context_for_online_action_detection_in_videos_Paper.pdf) - Vasiliki I. Vasileiou et al, `EUSIPCO 2021`.
- <span id = "2109">[FATSnet]</span> [**Temporally Smooth Online Action Detection using Cycle-consistent Future Anticipation**](https://arxiv.org/abs/2104.08030) - Young Hwi Kim et al, `PR 2021`. [[code]](https://github.com/YHKimGithub/FATSnet)

### <span id = "oad-2020"> 2020 </span>
- <span id = "2001">[IDN]</span> [**Learning to Discriminate Information for Online Action Detection**](https://openaccess.thecvf.com/content_CVPR_2020/papers/Eun_Learning_to_Discriminate_Information_for_Online_Action_Detection_CVPR_2020_paper.pdf) - Hyunjun Eun et al, `CVPR 2020`.[[code]](https://github.com/hjeun/idu)
- <span id = "2002">[LAP-Net]</span> [**LAP-Net: Adaptive Features Sampling via Learning Action Progression for Online Action Detection**](https://arxiv.org/abs/2011.07915) - Sanqing Qu et al, `ArXiv 2020`.
- <span id = "2003">[BF-I3D]</span> [**Online Action Detection in Streaming Videos with Time Buffers**](https://arxiv.org/abs/2011.07915) - Bowen Zhan et al, `ArXiv 2020`.
- <span id = "2004">[evaluation protocol]</span> [**Rethinking Online Action Detection in Untrimmed Videos: A Novel Online Evaluation Protocol**](https://arxiv.org/abs/2003.12041) - Marcos Baptista Rios et al, `IEEE Access 2020`.[[code]](https://github.com/gramuah/ia)

### <span id = "oad-2019"> 2019 </span>
- <span id = "1901">[TRN]</span> [**Temporal Recurrent Networks for Online Action Detection**](https://openaccess.thecvf.com/content_ICCV_2019/papers/Xu_Temporal_Recurrent_Networks_for_Online_Action_Detection_ICCV_2019_paper.pdf) - Mingze Xu et al, `ICCV 2019`.[[code]](https://github.com/xumingze0308/TRN.pytorch)
- <span id = "1902">[StartNet]</span> [**StartNet: Online Detection of Action Start in Untrimmed Videos**](https://openaccess.thecvf.com/content_ICCV_2019/papers/Gao_StartNet_Online_Detection_of_Action_Start_in_Untrimmed_Videos_ICCV_2019_paper.pdf) - Mingfei Gao et al, `ICCV 2019`.

### <span id = "oad-2018"> 2018 </span>
- <span id = "1801"></span> [**Modeling temporal structure with LSTM for online action detection**](https://ieeexplore.ieee.org/document/8354277) - Roeland De Geest et al, `WACV 2018`.
- <span id = "1802"></span> [**Online Detection of Action Start in Untrimmed, Streaming Video**](https://openaccess.thecvf.com/content_ECCV_2018/papers/Zheng_Shou_Online_Detection_of_ECCV_2018_paper.pdf) - Zheng Shou et al, `ECCV 2018`.[[code]](https://github.com/junting/odas)
- <span id = "1803">[HDD Dataset]</span> [**Toward Driving Scene Understanding: A Dataset for Learning Driver Behavior and Causal Reasoning**](https://openaccess.thecvf.com/content_cvpr_2018/papers/Ramanishka_Toward_Driving_Scene_CVPR_2018_paper.pdf) - Vasili Ramanishka et al, `CVPR 2018`.

### <span id = "oad-2017"> 2017 </span>
- <span id = "1701">[RED]</span> [**RED: Reinforced Encoder-Decoder Networks for Action Anticipation**](http://www.bmva.org/bmvc/2017/papers/paper092/paper092.pdf) - Jiyang Gao et al, `BMVC 2017`.

### <span id = "oad-2016"> 2016 </span>
- <span id = "1601">[Online action detection & TVseries Dataset]</span> [**Online Action Detection**](https://arxiv.org/abs/1604.06506) - Roeland De Geest et al, `ECCV 2016`.


### Comments are welcome for additional notesÔºÅ
